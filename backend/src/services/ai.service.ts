import { prisma } from "../utils/prisma";
import conversationExampleService from "./conversation-example.service";
import openaiService from "./ai-providers/openai.service";
import anthropicService from "./ai-providers/anthropic.service";
import { AIProvider } from "../types/ai-provider";
import { essentialTools } from "./ai-tools";

/**
 * ============================================
 * CONFIGURA√á√ïES DO CHATBOT - VALORES OTIMIZADOS
 * ============================================
 * Estas configura√ß√µes foram otimizadas para melhor performance
 * de um chatbot profissional de atendimento ao cliente.
 * N√ÉO s√£o configur√°veis pelo cliente final.
 */
const CHATBOT_CONFIG = {
  // ===== JANELA DE CONTEXTO =====
  // N√∫mero m√°ximo de mensagens a buscar do banco
  // Usado como limite inicial antes de aplicar otimiza√ß√µes
  MAX_MESSAGES_TO_FETCH: 20,

  // ===== LIMITE DE TOKENS DO HIST√ìRICO =====
  // M√°ximo de tokens permitidos para o hist√≥rico de mensagens
  // GPT-4o Mini tem 128k de contexto, mas reservamos espa√ßo para:
  // - System prompt (~1500 tokens)
  // - Resposta (~400 tokens)
  // - Margem de seguran√ßa
  MAX_HISTORY_TOKENS: 2000,

  // ===== TEMPERATURA =====
  // Controla criatividade vs consist√™ncia das respostas
  // 0.0 = muito determin√≠stico, sempre mesma resposta
  // 0.3-0.5 = consistente mas com varia√ß√£o natural (IDEAL PARA ATENDIMENTO)
  // 0.7-1.0 = mais criativo, pode variar muito
  TEMPERATURE: 0.4,

  // ===== MAX TOKENS DE RESPOSTA =====
  // Limite m√°ximo de tokens na resposta da IA
  // 300 = respostas curtas e diretas (ideal WhatsApp)
  // 500 = respostas m√©dias com mais detalhes
  // 800 = respostas longas para explica√ß√µes complexas
  MAX_TOKENS: 400,

  // ===== CONFIGURA√á√ïES DE RETRY =====
  // Tentativas em caso de falha na API
  MAX_RETRIES: 2,
  RETRY_DELAY_MS: 1000,

  // ===== MODELO PADR√ÉO =====
  // Modelo usado quando n√£o especificado
  DEFAULT_MODEL: "gpt-4o-mini",

  // ===== PRESEN√áA E FREQU√äNCIA =====
  // Penalidades para evitar repeti√ß√µes
  // 0 = sem penalidade, 2.0 = m√°xima penalidade
  PRESENCE_PENALTY: 0.1,  // Evita repetir t√≥picos j√° mencionados
  FREQUENCY_PENALTY: 0.1, // Evita repetir palavras/frases
};

/**
 * ============================================
 * UTILIT√ÅRIOS DE CONTAGEM DE TOKENS
 * ============================================
 * Estimativa de tokens usando regra pr√°tica:
 * ~4 caracteres = 1 token (para portugu√™s)
 * ~0.75 palavras = 1 token
 */

/**
 * Estima o n√∫mero de tokens em um texto
 * Usa aproxima√ß√£o: 1 token ‚âà 4 caracteres para portugu√™s
 */
function estimateTokens(text: string): number {
  if (!text) return 0;
  // Regra pr√°tica: ~4 caracteres por token em portugu√™s
  // Considera tamb√©m espa√ßos e pontua√ß√£o
  return Math.ceil(text.length / 4);
}

/**
 * Interface para mensagem agrupada
 */
interface GroupedMessage {
  sender: string;
  senderType: string;
  messages: string[];
  hasMedia: boolean;
  mediaTypes: string[];
  tokenCount: number;
}

class AIService {
  /**
   * Obt√©m o provedor de IA configurado
   */
  private getProvider(providerName?: AIProvider) {
    // Usa o provedor especificado ou o padr√£o do .env
    const provider = providerName || (process.env.AI_PROVIDER as AIProvider) || "openai";

    switch (provider) {
      case "openai":
        return openaiService;
      case "anthropic":
        return anthropicService;
      default:
        console.warn(`Unknown AI provider: ${provider}. Falling back to OpenAI.`);
        return openaiService;
    }
  }

  /**
   * Gera resposta autom√°tica usando o provedor configurado
   */
  async generateResponse(
    customerId: string,
    message: string,
    options?: { provider?: AIProvider; model?: string; temperature?: number; maxTokens?: number }
  ): Promise<string> {
    try {
      // Busca o customer com informa√ß√µes da empresa
      const customer = await prisma.customer.findUnique({
        where: { id: customerId },
        include: {
          company: {
            include: {
              aiKnowledge: true,
            },
          },
        },
      });

      if (!customer) {
        throw new Error("Customer not found");
      }

      // üéØ JANELA DE CONTEXTO DESLIZANTE COM OTIMIZA√á√ÉO
      // Busca mais mensagens do que precisamos para ter margem de otimiza√ß√£o
      const messages = await prisma.message.findMany({
        where: { customerId },
        orderBy: { timestamp: "desc" },
        take: CHATBOT_CONFIG.MAX_MESSAGES_TO_FETCH,
        include: {
          customer: true,
        },
      });

      // Inverte para ordem cronol√≥gica (mais antiga primeiro)
      const messageHistory = messages.reverse();

      // Monta o contexto da empresa
      const aiKnowledge = customer.company.aiKnowledge;

      // Verifica se resposta autom√°tica est√° habilitada
      // Por padr√£o, a IA responde EXCETO se autoReplyEnabled === false explicitamente
      if (aiKnowledge && aiKnowledge.autoReplyEnabled === false) {
        throw new Error("Auto-reply is disabled for this company");
      }

      // Contexto do neg√≥cio vem do cadastro do cliente
      const companyInfo = aiKnowledge?.companyInfo || "Informa√ß√µes da empresa n√£o dispon√≠veis.";
      const productsServices = aiKnowledge?.productsServices || "Produtos/servi√ßos n√£o especificados.";
      const policies = aiKnowledge?.policies || "";
      const negativeExamples = aiKnowledge?.negativeExamples || null;
      const serviceArea = aiKnowledge?.serviceArea || null;
      const workingHours = aiKnowledge?.workingHours || null;
      const paymentMethods = aiKnowledge?.paymentMethods || null;
      const deliveryInfo = aiKnowledge?.deliveryInfo || null;

      // Pega configura√ß√µes avan√ßadas da IA
      // NOTA: temperatura e maxTokens usam valores otimizados fixos (n√£o configur√°veis pelo cliente)
      const providerConfig = aiKnowledge?.provider as AIProvider | undefined;
      const modelConfig = aiKnowledge?.model ?? CHATBOT_CONFIG.DEFAULT_MODEL;
      const temperature = CHATBOT_CONFIG.TEMPERATURE;
      const maxTokens = CHATBOT_CONFIG.MAX_TOKENS;

      // üéØ OTIMIZA√á√ÉO: Agrupa mensagens sequenciais do mesmo remetente
      // e aplica limite de tokens para n√£o estourar contexto
      const { historyText, stats } = this.buildOptimizedHistory(messageHistory, customer.name);

      console.log(`[AIService] Context stats: ${stats.totalMessages} msgs ‚Üí ${stats.groupedBlocks} blocks, ~${stats.totalTokens} tokens`);

      // Busca exemplos de conversas exemplares (limitado para otimiza√ß√£o)
      const examplesText = await conversationExampleService.getExamplesForPrompt(customer.companyId);

      // Monta o prompt otimizado para GPT-4o Mini
      // Comportamento b√°sico √© hardcoded, contexto do neg√≥cio vem do cliente
      const systemPrompt = this.buildOptimizedPrompt({
        companyName: customer.company.name,
        companyInfo,
        productsServices,
        policies,
        examplesText,
        negativeExamples,
        serviceArea,
        workingHours,
        paymentMethods,
        deliveryInfo,
        customerName: customer.name,
        customerPhone: customer.phone,
        customerEmail: customer.email,
        customerTags: customer.tags,
        customerNotes: customer.notes,
      });

      const userPrompt = this.buildUserPrompt(historyText, message);

      // Seleciona e usa o provedor (prioriza configura√ß√£o da empresa)
      const providerName = options?.provider || providerConfig || (process.env.AI_PROVIDER as AIProvider) || "openai";
      const provider = this.getProvider(providerName);

      if (!provider.isConfigured()) {
        throw new Error(`AI provider is not configured. Please check your environment variables.`);
      }

      const lastMessage = messageHistory[messageHistory.length - 1];
      let imageUrlForVision: string | undefined = undefined;

      // Se a √∫ltima mensagem do cliente for uma imagem, passamos para a IA analisar
      if (lastMessage && lastMessage.direction === "INBOUND" && lastMessage.mediaType === "image" && lastMessage.mediaUrl) {
        imageUrlForVision = lastMessage.mediaUrl;
        console.log("[AIService] Image detected, enabling Vision capabilities");
      }

      // üéØ Function Calling: Passa tools apenas para OpenAI (Anthropic n√£o suporta ainda)
      const useTools = providerName === "openai" || (options?.provider || providerConfig) === "openai";

      const aiResponse = await provider.generateResponse({
        systemPrompt,
        userPrompt,
        temperature,
        maxTokens,
        model: options?.model || modelConfig,
        imageUrl: imageUrlForVision,
        // Adiciona tools e contexto para Function Calling
        ...(useTools && {
          tools: essentialTools,
          toolChoice: "auto", // IA decide quando usar
          context: {
            customerId: customer.id,
            companyId: customer.companyId,
          },
        }),
      });

      // Remove qualquer formata√ß√£o Markdown que a IA possa ter usado
      const cleanResponse = this.removeMarkdown(aiResponse);

      return cleanResponse;
    } catch (error: any) {
      console.error("AI Error:", error.message);
      throw new Error(`Failed to generate AI response: ${error.message}`);
    }
  }

  /**
   * Constr√≥i hist√≥rico otimizado com agrupamento e limite de tokens
   *
   * Otimiza√ß√µes:
   * 1. Agrupa mensagens sequenciais do mesmo remetente
   * 2. Aplica limite de tokens para n√£o estourar contexto
   * 3. Prioriza mensagens mais recentes
   */
  private buildOptimizedHistory(
    messageHistory: any[],
    customerName: string
  ): { historyText: string; stats: { totalMessages: number; groupedBlocks: number; totalTokens: number } } {
    if (!messageHistory || messageHistory.length === 0) {
      return {
        historyText: "(In√≠cio da conversa)",
        stats: { totalMessages: 0, groupedBlocks: 0, totalTokens: 0 },
      };
    }

    // 1. Agrupa mensagens sequenciais do mesmo remetente
    const groupedMessages: GroupedMessage[] = [];
    let currentGroup: GroupedMessage | null = null;

    for (const msg of messageHistory) {
      const isInbound = msg.direction === "INBOUND";
      const sender = isInbound ? customerName : "Assistente";
      const senderType = isInbound ? "customer" : (msg.senderType === "HUMAN" ? "human" : "ai");

      // Detecta m√≠dia
      const mediaType = msg.mediaType || null;

      if (currentGroup && currentGroup.sender === sender && currentGroup.senderType === senderType) {
        // Mesma pessoa, adiciona √† mensagem atual
        currentGroup.messages.push(msg.content);
        if (mediaType) {
          currentGroup.hasMedia = true;
          if (!currentGroup.mediaTypes.includes(mediaType)) {
            currentGroup.mediaTypes.push(mediaType);
          }
        }
      } else {
        // Nova pessoa, cria novo grupo
        if (currentGroup) {
          groupedMessages.push(currentGroup);
        }
        currentGroup = {
          sender,
          senderType,
          messages: [msg.content],
          hasMedia: !!mediaType,
          mediaTypes: mediaType ? [mediaType] : [],
          tokenCount: 0,
        };
      }
    }

    // Adiciona √∫ltimo grupo
    if (currentGroup) {
      groupedMessages.push(currentGroup);
    }

    // 2. Calcula tokens e formata cada bloco
    const formattedBlocks: string[] = [];
    let totalTokens = 0;

    // Processa do mais recente para o mais antigo (para priorizar recentes)
    const reversedGroups = [...groupedMessages].reverse();

    for (const group of reversedGroups) {
      // Formata o bloco
      let senderLabel = group.sender;
      if (group.senderType === "human") {
        senderLabel += " (Atendente)";
      }

      // Indicador de m√≠dia
      let mediaIndicator = "";
      if (group.hasMedia) {
        if (group.mediaTypes.includes("audio")) mediaIndicator += " üé§";
        if (group.mediaTypes.includes("image")) mediaIndicator += " üì∑";
      }

      // Une mensagens do mesmo remetente com quebra de linha simples
      const content = group.messages.join("\n");
      const blockText = `${senderLabel}${mediaIndicator}: ${content}`;

      // Calcula tokens do bloco
      const blockTokens = estimateTokens(blockText);

      // Verifica se ainda cabe no limite
      if (totalTokens + blockTokens > CHATBOT_CONFIG.MAX_HISTORY_TOKENS) {
        // N√£o cabe mais, para de adicionar
        console.log(`[AIService] Token limit reached (${totalTokens}/${CHATBOT_CONFIG.MAX_HISTORY_TOKENS}), stopping at ${formattedBlocks.length} blocks`);
        break;
      }

      formattedBlocks.unshift(blockText); // Adiciona no in√≠cio para manter ordem cronol√≥gica
      totalTokens += blockTokens;
      group.tokenCount = blockTokens;
    }

    // 3. Junta todos os blocos
    const historyText = formattedBlocks.join("\n\n");

    return {
      historyText,
      stats: {
        totalMessages: messageHistory.length,
        groupedBlocks: formattedBlocks.length,
        totalTokens,
      },
    };
  }

  /**
   * Remove formata√ß√£o Markdown da resposta da IA
   * WhatsApp n√£o renderiza markdown, ent√£o removemos para evitar ** e _ aparecendo no texto
   */
  private removeMarkdown(text: string): string {
    return (
      text
        // Remove bold: **texto** ou __texto__
        .replace(/\*\*(.+?)\*\*/g, "$1")
        .replace(/__(.+?)__/g, "$1")
        // Remove italic: *texto* ou _texto_
        .replace(/\*(.+?)\*/g, "$1")
        .replace(/_(.+?)_/g, "$1")
        // Remove strikethrough: ~~texto~~
        .replace(/~~(.+?)~~/g, "$1")
        // Remove code: `texto`
        .replace(/`(.+?)`/g, "$1")
        // Remove headers: # texto
        .replace(/^#+\s+/gm, "")
        // Remove listas: - item ou * item
        .replace(/^[\*\-]\s+/gm, "")
        // Remove links: [texto](url)
        .replace(/\[(.+?)\]\(.+?\)/g, "$1")
        // Remove > (quote)
        .replace(/^>\s+/gm, "")
    );
  }

  /**
   * Constr√≥i prompt otimizado para chatbot profissional
   *
   * ESTRUTURA DO PROMPT:
   * 1. IDENTIDADE - Quem √© a IA (hardcoded)
   * 2. CONTEXTO DO NEG√ìCIO - Vem do cadastro do cliente
   * 3. COMPORTAMENTO - Regras de conduta (hardcoded)
   * 4. SEGURAN√áA - Prote√ß√µes (hardcoded)
   * 5. DADOS DO CLIENTE - Info do contato atual
   */
  private buildOptimizedPrompt(data: any): string {
    const {
      companyName,
      companyInfo,
      productsServices,
      policies,
      negativeExamples,
      serviceArea,
      workingHours,
      paymentMethods,
      deliveryInfo,
      customerName,
    } = data;

    // ========================================
    // SE√á√ÉO 1: IDENTIDADE (HARDCODED)
    // ========================================
    const identitySection = `VOC√ä √â: Assistente Virtual da ${companyName}
FUN√á√ÉO: Atendimento ao cliente via WhatsApp

Voc√™ √© um atendente virtual inteligente, profissional e prestativo.
Seu objetivo √© ajudar os clientes com informa√ß√µes, tirar d√∫vidas e encaminhar para atendimento humano quando necess√°rio.`;

    // ========================================
    // SE√á√ÉO 2: CONTEXTO DO NEG√ìCIO (DO CLIENTE)
    // ========================================
    let businessContext = `\n# üìã INFORMA√á√ïES DA EMPRESA\n`;
    businessContext += companyInfo || "Empresa de atendimento ao cliente.";

    businessContext += `\n\n# üõí PRODUTOS E SERVI√áOS\n`;
    businessContext += productsServices || "Consulte o atendente para informa√ß√µes sobre produtos e servi√ßos.";

    // Informa√ß√µes operacionais
    if (workingHours || paymentMethods || deliveryInfo || policies) {
      businessContext += `\n\n# ‚öôÔ∏è INFORMA√á√ïES OPERACIONAIS\n`;
      if (workingHours) businessContext += `**Hor√°rio de Atendimento:** ${workingHours}\n`;
      if (paymentMethods) businessContext += `**Formas de Pagamento:** ${paymentMethods}\n`;
      if (deliveryInfo) businessContext += `**Entrega/Prazos:** ${deliveryInfo}\n`;
      if (policies) businessContext += `**Pol√≠ticas:** ${policies}\n`;
    }

    // √Årea de atendimento
    if (serviceArea) {
      businessContext += `\n\n# üìç √ÅREA DE ATENDIMENTO\n`;
      businessContext += `A empresa atende nas seguintes regi√µes:\n${serviceArea}\n\n`;
      businessContext += `‚ö†Ô∏è IMPORTANTE: Antes de agendar servi√ßos presenciais, SEMPRE pergunte o bairro/cidade/CEP do cliente e verifique se est√° dentro da √°rea de atendimento.`;
    }

    // O que n√£o fazer (configurado pelo cliente)
    if (negativeExamples) {
      businessContext += `\n\n# ‚ùå O QUE N√ÉO FAZER\n${negativeExamples}`;
    }

    // ========================================
    // SE√á√ÉO 3: COMPORTAMENTO (HARDCODED)
    // ========================================
    const behaviorSection = `
# üí¨ COMPORTAMENTO PROFISSIONAL

## Tom de Comunica√ß√£o
- Seja educado, profissional e acolhedor
- Use linguagem clara, objetiva e f√°cil de entender
- Trate o cliente com respeito, usando "voc√™" ou o nome dele
- Respostas diretas sem enrola√ß√£o

## Estrutura das Respostas
- Respostas curtas (m√°ximo 3-4 linhas por bloco)
- Use quebras de linha para organizar informa√ß√µes
- Uma pergunta por vez (n√£o sobrecarregue o cliente)
- N√ÉO use formata√ß√£o Markdown (*, **, _, etc.)
- Se j√° houver hist√≥rico, N√ÉO repita sauda√ß√µes

## Emojis
- Use com modera√ß√£o (m√°ximo 2-3 por mensagem)
- Emojis profissionais: ‚úÖ üì¶ üí≥ ‚è∞
- Evite emojis informais ou excessivos

## Fluxo Natural
1. Cumprimente apenas na PRIMEIRA mensagem
2. Identifique a necessidade do cliente
3. Responda de forma objetiva
4. Ofere√ßa pr√≥ximo passo ou ajuda adicional`;

    // ========================================
    // SE√á√ÉO 4: SEGURAN√áA (HARDCODED)
    // ========================================
    const securitySection = `
# üîí REGRAS DE SEGURAN√áA (CR√çTICO)

## Sobre Valores e Prazos
- NUNCA invente pre√ßos, valores ou prazos
- S√ì informe o que est√° cadastrado em "PRODUTOS E SERVI√áOS"
- Se n√£o souber o pre√ßo: "Preciso verificar o valor atualizado. Posso solicitar um or√ßamento?"
- NUNCA arredonde ou "chute" valores

## Informa√ß√µes Proibidas - NUNCA REVELE
- Dados financeiros da empresa (faturamento, lucros, custos)
- Dados pessoais de funcion√°rios ou outros clientes
- Senhas, acessos ou informa√ß√µes t√©cnicas internas
- Problemas t√©cnicos ou erros do sistema
- Para o cliente, tudo funciona normalmente

## Assuntos Proibidos - NUNCA DISCUTA
- Pol√≠tica, religi√£o ou temas pol√™micos
- Opini√µes pessoais
- Compara√ß√µes negativas com concorrentes

Se perguntarem sobre assunto proibido:
"Desculpe, n√£o posso ajudar com esse assunto. Posso te ajudar com informa√ß√µes sobre nossos produtos e servi√ßos!"`;

    // ========================================
    // SE√á√ÉO 5: A√á√ïES ESPECIAIS (HARDCODED)
    // ========================================
    const actionsSection = `
# üìÖ AGENDAMENTOS

Use [INICIAR_AGENDAMENTO] APENAS quando:
- Cliente diz EXPLICITAMENTE que quer agendar
- Voc√™ j√° informou o servi√ßo e valor
- J√° verificou se est√° na √°rea de atendimento

NUNCA use quando o cliente est√° apenas tirando d√∫vidas ou comparando op√ß√µes.

Formato: [INICIAR_AGENDAMENTO] Sua mensagem aqui...

# üö® TRANSBORDO PARA HUMANO

Use [TRANSBORDO] quando:
- Cliente pede para falar com humano/atendente
- Reclama√ß√µes graves ou cliente insatisfeito
- Problemas com pagamento, garantia ou devolu√ß√£o
- Situa√ß√µes que voc√™ n√£o consegue resolver

Formato: [TRANSBORDO] Vou transferir voc√™ para um especialista. Um momento!`;

    // ========================================
    // SE√á√ÉO 6: DADOS DO CLIENTE
    // ========================================
    const customerSection = `
# üë§ CLIENTE ATUAL
Nome: ${customerName}${data.customerTags?.length ? `\nTags: ${data.customerTags.join(", ")}` : ""}${data.customerNotes ? `\nObserva√ß√µes: ${data.customerNotes}` : ""}`;

    // ========================================
    // MONTA O PROMPT FINAL
    // ========================================
    return `${identitySection}
${businessContext}
${behaviorSection}
${securitySection}
${actionsSection}
${customerSection}

Responda de forma natural e conversacional:`;
  }

  /**
   * Constr√≥i prompt do usu√°rio
   */
  private buildUserPrompt(historyText: string, currentMessage: string): string {
    // Adiciona data/hora atual para no√ß√£o temporal
    const now = new Date().toLocaleString("pt-BR", { timeZone: "America/Sao_Paulo" });

    return `DATA/HORA ATUAL: ${now}

# HIST√ìRICO DA CONVERSA (Mensagens Anteriores)
${historyText ? historyText : "(In√≠cio da conversa)"}

# MENSAGEM ATUAL DO CLIENTE
${currentMessage}

Sua resposta (lembre-se: sem 'Oi' repetitivo se j√° houver hist√≥rico):`;
  }

  /**
   * Verifica se algum provedor est√° configurado
   */
  isConfigured(): boolean {
    return openaiService.isConfigured() || anthropicService.isConfigured();
  }

  /**
   * Retorna informa√ß√µes sobre o provedor atual
   */
  getCurrentProviderInfo() {
    const providerName = (process.env.AI_PROVIDER as AIProvider) || "openai";
    const provider = this.getProvider(providerName);
    return provider.getModelInfo();
  }

  /**
   * Lista todos os provedores dispon√≠veis
   */
  getAvailableProviders() {
    return [
      {
        name: "openai",
        configured: openaiService.isConfigured(),
        info: openaiService.getModelInfo(),
      },
      {
        name: "anthropic",
        configured: anthropicService.isConfigured(),
        info: anthropicService.getModelInfo(),
      },
    ];
  }
}

export default new AIService();
